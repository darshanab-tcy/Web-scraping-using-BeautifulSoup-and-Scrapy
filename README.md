# Web Scraping using BeautifulSoup and Scrapy

This repository demonstrates web scraping techniques using **BeautifulSoup** and **Scrapy** in Python.  
The project focuses on extracting structured data from a publicly available website and exporting it to CSV format.

---

## ğŸ“Œ Objectives
- Demonstrate static web scraping using BeautifulSoup.
- Implement pagination handling.
- Demonstrate scalable scraping using Scrapy.
- Store scraped data in structured CSV files.

---

## ğŸŒ Website Used
- https://quotes.toscrape.com  
This website is intended for scraping practice and does not require authentication.
---

## ğŸ§° Tools & Libraries
- Python
- BeautifulSoup
- Requests
- Scrapy
- Pandas
- Jupyter Notebook

---

## ğŸ“‚ Project Structure

Web-scraping-using-BeautifulSoup-and-Scrapy/
â”‚
â”œâ”€â”€ Webscraping using BeautifulSoup/
â”‚ â”œâ”€â”€ Web scraping using BeautifulSoup.ipynb
â”‚ â””â”€â”€ data/
â”‚ â”œâ”€â”€ quotes.csv
â”‚ â””â”€â”€ quotes_bs4.csv
â”‚
â”œâ”€â”€ Web scraping using Scrapy/
â”‚ â”œâ”€â”€ scrapy/
â”‚ â”‚ â””â”€â”€ quotes_spider.py
â”‚ â””â”€â”€ data/
â”‚ â””â”€â”€ quotes_scrapy.csv
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

## ğŸŸ¢ BeautifulSoup Scraping
- Sends HTTP requests to static web pages.
- Parses HTML using BeautifulSoup.
- Extracts quote text, author, and tags.
- Handles pagination by detecting "Next" links.
- Saves results to CSV using Pandas.

---

## ğŸ”µ Scrapy Scraping
- Uses Scrapy spider for structured crawling.
- Automatically handles pagination.
- Faster and more scalable than manual scraping.
- Outputs data directly to CSV.

---

## ğŸ“Š Output Data
- Quote text
- Author name
- Associated tags

---

## ğŸ“ Notes
- This project focuses on **static web scraping**.
- No browser automation was used.

---

## âœ… Key Takeaways
- BeautifulSoup is suitable for simple to medium scraping tasks.
- Scrapy is preferred for larger, scalable scraping pipelines.
- Proper project structure and version control are essential.
